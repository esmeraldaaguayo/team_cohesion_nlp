{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "import gensim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60425\n",
      "                                             comment label\n",
      "0  Yeah, but I don't like to post that until *aft...   neg\n",
      "1                                Cool. Thank you :-)   pos\n",
      "2  Thanks -- I thought the slides were pretty goo...   pos\n",
      "3    Edy, 4.2-milestone-1 hasn't been released yet..   pos\n",
      "4  ^^ sorry but your index.php don't work with me...   pos\n",
      "5                                                 ;(   pos\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('output/train_corpus.pkl', 'rb') as f:\n",
    "    train_corpus = pickle.load(f)\n",
    "with open('output/train_id2word.pkl', 'rb') as f:\n",
    "    train_id2word = pickle.load(f)\n",
    "with open('output/train_bigram.pkl', 'rb') as f:\n",
    "    train_bigram = pickle.load(f)\n",
    "    \n",
    "text_comments = pd.read_csv('data/labeled_commit_comments.csv')\n",
    "text_comments.comment = text_comments.comment.astype(str)\n",
    "documents_train = text_comments[['comment']][:60425].astype(str)\n",
    "documents_train['label'] = text_comments['label'][:60425]\n",
    "print(len(documents_train))\n",
    "print(documents_train[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide greater visibility during training\n",
    "logging.basicConfig(filename='output/lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    lda_train = gensim.models.LdaMulticore(corpus=train_corpus, num_topics=20, id2word=train_id2word, workers=2, passes=2)\n",
    "    lda_train.save('output/lda_train.model')\n",
    "    \n",
    "    lda_train.print_topics(20, num_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.037*\"know\" + 0.028*\"data\" + 0.019*\"work\" + 0.018*\"like\" + 0.017*\"self\" + 0.015*\"think\" + 0.015*\"templat\" + 0.014*\"need\" + 0.013*\"thing\" + 0.012*\"error\" + 0.011*\"warn\" + 0.011*\"index\" + 0.010*\"want\" + 0.009*\"model\" + 0.009*\"variabl\"'),\n",
       " (1,\n",
       "  '0.063*\"method\" + 0.024*\"mean\" + 0.021*\"call\" + 0.020*\"need\" + 0.017*\"return\" + 0.014*\"java\" + 0.013*\"thread\" + 0.013*\"queri\" + 0.011*\"connect\" + 0.011*\"tabl\" + 0.011*\"like\" + 0.010*\"match\" + 0.010*\"http\" + 0.009*\"string\" + 0.009*\"option\"'),\n",
       " (2,\n",
       "  '0.069*\"file\" + 0.066*\"version\" + 0.026*\"error\" + 0.023*\"delet\" + 0.017*\"includ\" + 0.016*\"lgtm\" + 0.014*\"code\" + 0.014*\"prefer\" + 0.011*\"chang\" + 0.011*\"line\" + 0.009*\"save\" + 0.009*\"need\" + 0.009*\"debug\" + 0.008*\"print\" + 0.008*\"necessari\"'),\n",
       " (3,\n",
       "  '0.044*\"class\" + 0.043*\"check\" + 0.027*\"null\" + 0.023*\"true\" + 0.018*\"pass\" + 0.015*\"think\" + 0.015*\"paramet\" + 0.013*\"valu\" + 0.012*\"document\" + 0.012*\"case\" + 0.010*\"type\" + 0.010*\"test\" + 0.009*\"work\" + 0.008*\"better\" + 0.008*\"defin\"'),\n",
       " (4,\n",
       "  '0.056*\"http\" + 0.031*\"good\" + 0.022*\"like\" + 0.019*\"block\" + 0.016*\"style\" + 0.014*\"string\" + 0.014*\"chang\" + 0.014*\"import\" + 0.013*\"code\" + 0.012*\"replac\" + 0.012*\"html\" + 0.012*\"work\" + 0.011*\"help\" + 0.011*\"explain\" + 0.009*\"play\"'),\n",
       " (5,\n",
       "  '0.148*\"commit\" + 0.056*\"line\" + 0.035*\"http_github\" + 0.028*\"chang\" + 0.025*\"space\" + 0.016*\"fix\" + 0.012*\"diff\" + 0.012*\"add\" + 0.011*\"indent\" + 0.010*\"previou\" + 0.010*\"correct\" + 0.009*\"text\" + 0.009*\"filter\" + 0.009*\"final\" + 0.008*\"note\"'),\n",
       " (6,\n",
       "  '0.061*\"chang\" + 0.037*\"nice\" + 0.033*\"merg\" + 0.022*\"need\" + 0.020*\"request\" + 0.019*\"event\" + 0.016*\"think\" + 0.014*\"valu\" + 0.013*\"agre\" + 0.012*\"like\" + 0.012*\"reason\" + 0.011*\"work\" + 0.011*\"problem\" + 0.009*\"start\" + 0.009*\"packag\"'),\n",
       " (7,\n",
       "  '0.099*\"issu\" + 0.036*\"look\" + 0.032*\"pull_request\" + 0.030*\"pull\" + 0.024*\"close\" + 0.024*\"http_github\" + 0.012*\"crash\" + 0.012*\"see\" + 0.011*\"good_idea\" + 0.010*\"fine\" + 0.010*\"chang\" + 0.009*\"size\" + 0.009*\"open\" + 0.008*\"devic\" + 0.007*\"weird\"'),\n",
       " (8,\n",
       "  '0.066*\"remov\" + 0.030*\"updat\" + 0.026*\"need\" + 0.023*\"page\" + 0.021*\"cool\" + 0.018*\"modul\" + 0.014*\"disabl\" + 0.014*\"except\" + 0.013*\"think\" + 0.013*\"case\" + 0.013*\"statement\" + 0.013*\"translat\" + 0.012*\"hash\" + 0.011*\"plan\" + 0.010*\"button\"'),\n",
       " (9,\n",
       "  '0.059*\"fix\" + 0.031*\"code\" + 0.021*\"add\" + 0.021*\"rail\" + 0.021*\"messag\" + 0.019*\"like\" + 0.017*\"send\" + 0.015*\"config\" + 0.013*\"color\" + 0.013*\"argument\" + 0.011*\"think\" + 0.011*\"chang\" + 0.009*\"split\" + 0.009*\"target\" + 0.008*\"account\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.print_topics(20,num_words=15)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make feature vectors\n",
    "train_vecs = []\n",
    "for i in range(len(documents_train)):\n",
    "    top_topics = lda_train.get_document_topics(train_corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(20)]\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60425\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.312089,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.34650117,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.008334031,\n",
       " 0.19973129,\n",
       " 0.008334031]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_vecs))\n",
    "print(np.sum(train_vecs[2]))\n",
    "train_vecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60425, 20)\n",
      "(60425,)\n",
      "[0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(train_vecs)\n",
    "y = np.array([1 if value=='pos' else 0 for idx, value in documents_train.label.iteritems()])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "with open('output/y.pkl', 'wb') as f:\n",
    "    pickle.dump(y, f)\n",
    "with open('output/x.pkl', 'wb') as f:\n",
    "    pickle.dump(x, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
